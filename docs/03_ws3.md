# Workshop 3: *t*-Tests

**Aims:**

-   Practice running and interpreting a two-sample *t*-test in RStudio.

-   Practice running and interpreting a paired *t*-test in RStudio.

## Part One

Part one of today's workshop will involved running a two-sample t-test, which is appropriate for an independent measures design with **two** groups.

You should use the same data file from last week, as you will be aiming to answer "What impact does energy drink consumption (if any) have on sleep quality?"

## Exercise 1: Import the Data

**Import the Data File:** `sleep.csv`

Before you begin, you will need the tidyverse package loaded.

``` r
install.packages("tidyverse") #install if needed.
install.packages("rstatix")   #install if needed.
library(tidyverse)            #load package
library(rstatix)              #load package
```

Then import the data file. Make sure it has the `total_sleep` score that you calculated last week.

``` r
mydata <- read_csv("sleep.csv")
```

## Exercise 2: Inspect and Check Your Data

**Take a look at your newly imported data file**

Check the top right panel (the environment) and also use the code below to inspect your data set.

``` r
view(mydata) # this will open the data in a new tab.
names(mydata) # this will show the variable names.
```

It is really important to look at the variable names as you'll be using them in code later on.

## Exercise 3: Check Assumptions

### Check Heteroscedasticity with Levene's Test

Use Levene's test to check for homogeneity of variance.

``` r
leveneTest(DV ~ IV, data = DATA)
```

-   Change `DV` to the name of your dependent variable.
-   Change `IV` to the name of your independent (grouping) variable.
-   Change `DATA` to the name of your data.

Run the code and interpret the output:

If the p-value is significant (\<.05) then the variances differ across the two groups and the assumption has been violated, which could be an issue. If the p-value is *not* significant (\>.05) then the variances are roughly equal.

Write up as follows:

> *F*(df) = XX.XX, *p* = .XXX


Enter the degrees of freedom in place of `df`, the *F* value, and the *p*-value.
Remember use p <.001 if the p-value is smaller than 0.001.

Here is an example where degrees of freedom is 36, *F* is 3.25, and *p* is .065:

> *F*(36) = 3.25, *p* = .065

### Check Normality with Shapiro-Wilk Test and Histograms

We need to check normality for both groups separately. We can filter the groups:

```r
#first create a data set that contains energy drink consumers only.
yes <- mydata %>%
  filter(energy_drink == "yes")

#then run the test
shapiro.test(yes$total_sleep)

#then create a data set that contains non-consumers only.
no <- mydata %>%
  filter(energy_drink == "no")

#then run the test
shapiro.test(no$total_sleep)
```
We use a dollar sign `$` to point R to a particular column.
For example, when using `shapiro.test(yes$total_sleep)` you are saying to run the Shapiro Test on the `yes` data set column called `total_score`

Again, we want the *p*-values to be not significant. A non-significant *p*-value means the data are roughly normally distributed. If the *p*-value is significant, this could be an issue as it indicates the data are not normally distributed.

When reporting the Shapiro-Wilk test, you just need to report the test statistics (*w* = XX) and the *p*-value. Here is an example what it could look like:

> *W* = 0.98, *p* = .875

You can also visually check the data with a quick histogram:

```r
hist(yes$total_sleep)
hist(no$total_sleep)
```
Check the plots panel, and use the blue arrow to switch between the two plots.

### A Note on Assumptions

Assessing assumptions can be a little tricky. For a two-sample *t*-test we will run something called Welch's *t*-test which can cope with violations of assumptions.

You might ask what is the point of checking them. One reason is because it is helpful to report the characteristics (heteroscedasticity and normality) of your data. 

## Exercise 4: Run the Two-Sample *t*-Test and ask for Cohen's d

Run the *t*-test.

```r
t.test(total_sleep ~ energy_drink, data = mydata, var.equal = FALSE, alternative = "two.sided")
```

Ask for Cohen's d:

```r
cohens_d(data = mydata, total_sleep ~ energy_drink, var.equal = FALSE)
```

Interpret your *t*-test.
- Is it significant?
- What is the effect size?
- If significant, how do the groups differ?

For the final question, you will need descriptive statistics. Hint: use the code from last week to find the mean and standard deviation for the two groups.

## Part Two

Part two of today's workshop will involved running a paired t-test, which is appropriate for a repeated measures design with **two** conditions.

Here we have a sleep intervention study. A group of participants completed the sleep quality questionnaire **before** completing an intervention which aimed to improve sleep. Afterwards, participants completed the sleep questionnaire again.

The independent variable is time point: before, after.
The dependent variable is sleep quality score (0-100).

## Exercise 5: Import the Data

We will calle the object `int` (short for intervention data)

``` r
int <- read_csv("sleep_intervention.csv")
```

## Exercise 6: Inspect and Check Your Data

**Take a look at your newly imported data file**

Check the top right panel (the environment) and also use the code below to inspect your data set.

``` r
view(int) # this will open the data in a new tab.
names(int) # this will show the variable names.
```

## Exercise 7: Check Assumptions

This time we only have to check normality, as heteroscedasiticty does not apply to repeated measures designs. However, we need to ensure the difference score is normally distributed.

```r
diff <- int$post - int$pre  #this will calculate the difference score.
shapiro.test(diff)          # run the Shapiro test
hist(diff)                  # also visually inspect data
```

You should interpret and report this in the same way as earlier (exercise 3).

## Exercise 8: Run the Paired *t*-Test and ask for Cohen's d

A paired t-test is a little different compared to the two-sample t-test.

```r
t.test(NULL1, NULL2, paired = TRUE)
```

- Change `NULL1` to the column with the first condition.

- Change `NULL2` to the column with the second condition.

(Hint: you will need to use the dollar sign `$` to specify which column)

<details>

<summary>ðŸ‘€ Click for a hint</summary>

``` r
t.test(int$before, int$after, paired = TRUE)
```

</details>


Annoyingly, we need to use a different package for Cohen's d for a paired t-test.

```r
install.package("2effectsize") #install if needed.
library(effectsize)
effectsize::cohens_d(int$before, int$after, paired = TRUE)
```

## Exercise 9: Calculate Descriptive Statistics

The good news is that for a paired sample t-test, we can use the `summary()` function to obtain the descriptive statistics.

```r
summary(int)
```

Make note of the mean and standard deviation for the `before` and `after` conditions.

------------------------------------------------------------------------

**Well Done. You have reached the end of the workshop.**

------------------------------------------------------------------------
